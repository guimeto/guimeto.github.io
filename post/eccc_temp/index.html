<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.2">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Guillaume Dueymes">

  
  
  
    
  
  <meta name="description" content="Extract daily temperature from Environment Canada using Python The objective of this product is to retrieve daily temperature data from the second generation homogenized dataset of Environment and Climate Change Canada developed by Vincent et al. 2012.
Adjusted and homogenized Canadian climate dataset (DCCAH) were prepared to provide a better spatial and temporal representation of the climate trends in Canada.
In the Second Generation of Homogenized Temperature, new adjustments were applied to the daily minimum temperatures at synoptic stations (mainly airports) to address the bias due to the change in observing time in July 1961 (Vincent et al.">

  
  <link rel="alternate" hreflang="en-us" href="/post/eccc_temp/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/eccc_temp/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="GDueymes">
  <meta property="og:url" content="/post/eccc_temp/">
  <meta property="og:title" content="ECCC homogenized dataset | GDueymes">
  <meta property="og:description" content="Extract daily temperature from Environment Canada using Python The objective of this product is to retrieve daily temperature data from the second generation homogenized dataset of Environment and Climate Change Canada developed by Vincent et al. 2012.
Adjusted and homogenized Canadian climate dataset (DCCAH) were prepared to provide a better spatial and temporal representation of the climate trends in Canada.
In the Second Generation of Homogenized Temperature, new adjustments were applied to the daily minimum temperatures at synoptic stations (mainly airports) to address the bias due to the change in observing time in July 1961 (Vincent et al."><meta property="og:image" content="/post/eccc_temp/featured.jpg">
  <meta property="twitter:image" content="/post/eccc_temp/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-12-06T19:50:39-08:00">
    
    <meta property="article:modified_time" content="2019-12-06T19:50:39-08:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/eccc_temp/"
  },
  "headline": "ECCC homogenized dataset",
  
  "image": [
    "/post/eccc_temp/featured.jpg"
  ],
  
  "datePublished": "2019-12-06T19:50:39-08:00",
  "dateModified": "2019-12-06T19:50:39-08:00",
  
  "author": {
    "@type": "Person",
    "name": "Guillaume Dueymes"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "GDueymes",
    "logo": {
      "@type": "ImageObject",
      "url": "/img/icon-512.png"
    }
  },
  "description": "Extract daily temperature from Environment Canada using Python The objective of this product is to retrieve daily temperature data from the second generation homogenized dataset of Environment and Climate Change Canada developed by Vincent et al. 2012.\nAdjusted and homogenized Canadian climate dataset (DCCAH) were prepared to provide a better spatial and temporal representation of the climate trends in Canada.\nIn the Second Generation of Homogenized Temperature, new adjustments were applied to the daily minimum temperatures at synoptic stations (mainly airports) to address the bias due to the change in observing time in July 1961 (Vincent et al."
}
</script>

  

  


  


  





  <title>ECCC homogenized dataset | GDueymes</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">GDueymes</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/Guillaume_Dueymes2019.pdf"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>ECCC homogenized dataset</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Dec 6, 2019
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  

  
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 360px;">
  <div style="position: relative">
    <img src="/post/eccc_temp/featured_hud8ea7a49e8a1f32c574d7de110b22f60_104695_720x0_resize_q90_lanczos.jpg" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      

<h2 id="extract-daily-temperature-from-environment-canada-using-python">Extract daily temperature from Environment Canada using Python</h2>

<p>The objective of this product is to retrieve daily temperature data from the second generation homogenized dataset of Environment and Climate Change Canada developed by Vincent et al. 2012.</p>

<p>Adjusted and homogenized Canadian climate dataset (DCCAH) were prepared to provide a better spatial and temporal representation of the climate trends in Canada.</p>

<p>In the Second Generation of Homogenized Temperature, new adjustments were applied to the daily minimum temperatures at synoptic stations (mainly airports) to address the bias due to the change in observing time in July 1961 (Vincent et al. 2009).</p>

<p>Daily homogenized temperatures (minimum, maximum and mean) can be dowloaded on this <a href="ftp://ccrp.tor.ec.gc.ca/pub/EC_data/AHCCD_daily/" target="_blank">link</a>.</p>

<p>Raw dataset can be downloaded <a href="http://climate.weather.gc.ca/historical_data/search_historic_data_f.html" target="_blank">here</a>.</p>

<p>In this post, we will work on a specific province in Canada (using filters). To do this, we will use  Temperature_Stations.xls available on ftp site. This file provide us a list of all stations available.</p>

<p>We first need to import our librairies:</p>

<pre><code class="language-python">
import pandas as pd
import os
from datetime import date
import calendar
import numpy as np
import pathlib
import warnings
warnings.filterwarnings(&quot;ignore&quot;)
from itertools import islice
</code></pre>

<p>We will work with daily minimum temperature data only for the Northwest Territories of Canada.</p>

<p>Referring to the document Temperature_Stations.xls, we see that the acronym for this province is: NWT.</p>

<pre><code class="language-python">dataframe = pd.read_excel(&quot;./Temperature_Stations.xls&quot;, skiprows = range(0, 3))
dataframe.head()
</code></pre>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="left">Prov</th>
<th align="left">Nom de station</th>
<th align="right">stnid</th>
<th align="right">année déb.</th>
<th align="right">mois déb.</th>
<th align="right">année fin.</th>
<th align="right">mois fin.</th>
<th align="right">lat (deg)</th>
<th align="right">long (deg)</th>
<th align="right">élév (m)</th>
<th align="left">stns jointes</th>
</tr>
</thead>

<tbody>
<tr>
<td align="right">0</td>
<td align="left">BC</td>
<td align="left">AGASSIZ</td>
<td align="right">1100120</td>
<td align="right">1893</td>
<td align="right">1</td>
<td align="right">2018</td>
<td align="right">9</td>
<td align="right">49.25</td>
<td align="right">-121.77</td>
<td align="right">15</td>
<td align="left">N</td>
</tr>

<tr>
<td align="right">1</td>
<td align="left">BC</td>
<td align="left">ATLIN</td>
<td align="right">1200560</td>
<td align="right">1905</td>
<td align="right">8</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">59.57</td>
<td align="right">-133.7</td>
<td align="right">674</td>
<td align="left">N</td>
</tr>

<tr>
<td align="right">2</td>
<td align="left">BC</td>
<td align="left">BARKERVILLE</td>
<td align="right">1090660</td>
<td align="right">1888</td>
<td align="right">2</td>
<td align="right">2015</td>
<td align="right">3</td>
<td align="right">53.07</td>
<td align="right">-121.52</td>
<td align="right">1265</td>
<td align="left">N</td>
</tr>

<tr>
<td align="right">3</td>
<td align="left">BC</td>
<td align="left">BEAVERDELL</td>
<td align="right">1130771</td>
<td align="right">1939</td>
<td align="right">1</td>
<td align="right">2006</td>
<td align="right">9</td>
<td align="right">49.48</td>
<td align="right">-119.05</td>
<td align="right">838</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">4</td>
<td align="left">BC</td>
<td align="left">BELLA COOLA</td>
<td align="right">1060841</td>
<td align="right">1895</td>
<td align="right">5</td>
<td align="right">2017</td>
<td align="right">11</td>
<td align="right">52.37</td>
<td align="right">-126.68</td>
<td align="right">18</td>
<td align="left">Y</td>
</tr>
</tbody>
</table>

<p>Using this Dataframe we can define some input parameters to filter our data.</p>

<pre><code class="language-python">varin = 'dn'                          # variable acronym                                                                  
path = 'Homog_daily_min_temp_v2018'   # path to get data                                       
varout = 'Tasmin'                      
province = 'NWT'                      # Province to work with
</code></pre>

<p>We can now filter our dataset.</p>

<pre><code class="language-python">globals()['dataframe_'+province] = dataframe.loc[(dataframe[&quot;Prov&quot;] == province),:]
globals()['dataframe_'+province]
</code></pre>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="left">Prov</th>
<th align="left">Nom de station</th>
<th align="left">stnid</th>
<th align="right">année déb.</th>
<th align="right">mois déb.</th>
<th align="right">année fin.</th>
<th align="right">mois fin.</th>
<th align="right">lat (deg)</th>
<th align="right">long (deg)</th>
<th align="right">élév (m)</th>
<th align="left">stns jointes</th>
</tr>
</thead>

<tbody>
<tr>
<td align="right">65</td>
<td align="left">NWT</td>
<td align="left">CAPE PARRY</td>
<td align="left">2200675</td>
<td align="right">1957</td>
<td align="right">5</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">70.17</td>
<td align="right">-124.72</td>
<td align="right">87</td>
<td align="left">N</td>
</tr>

<tr>
<td align="right">66</td>
<td align="left">NWT</td>
<td align="left">FORT GOOD HOPE</td>
<td align="left">2201450</td>
<td align="right">1944</td>
<td align="right">8</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">66.23</td>
<td align="right">-128.65</td>
<td align="right">82</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">68</td>
<td align="left">NWT</td>
<td align="left">FORT RELIANCE</td>
<td align="left">2201903</td>
<td align="right">1948</td>
<td align="right">10</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">62.72</td>
<td align="right">-109.17</td>
<td align="right">168</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">69</td>
<td align="left">NWT</td>
<td align="left">FORT SIMPSON</td>
<td align="left">2202103</td>
<td align="right">1895</td>
<td align="right">11</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">61.77</td>
<td align="right">-121.23</td>
<td align="right">169</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">70</td>
<td align="left">NWT</td>
<td align="left">FORT SMITH</td>
<td align="left">2202201</td>
<td align="right">1913</td>
<td align="right">7</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">60.02</td>
<td align="right">-111.97</td>
<td align="right">205</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">71</td>
<td align="left">NWT</td>
<td align="left">HAY RIVER</td>
<td align="left">2202401</td>
<td align="right">1893</td>
<td align="right">9</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">60.83</td>
<td align="right">-115.78</td>
<td align="right">166</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">72</td>
<td align="left">NWT</td>
<td align="left">INUVIK</td>
<td align="left">2202578</td>
<td align="right">1957</td>
<td align="right">3</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">68.3</td>
<td align="right">-133.48</td>
<td align="right">103</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">73</td>
<td align="left">NWT</td>
<td align="left">MOULD BAY</td>
<td align="left">250M001</td>
<td align="right">1948</td>
<td align="right">5</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">76.23</td>
<td align="right">-119.35</td>
<td align="right">2</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">74</td>
<td align="left">NWT</td>
<td align="left">NORMAN WELLS</td>
<td align="left">2202801</td>
<td align="right">1943</td>
<td align="right">5</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">65.28</td>
<td align="right">-126.8</td>
<td align="right">73</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">75</td>
<td align="left">NWT</td>
<td align="left">SACHS HARBOUR</td>
<td align="left">2503648</td>
<td align="right">1955</td>
<td align="right">11</td>
<td align="right">2018</td>
<td align="right">8</td>
<td align="right">72</td>
<td align="right">-125.27</td>
<td align="right">86</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">76</td>
<td align="left">NWT</td>
<td align="left">TUKTOYAKTUK</td>
<td align="left">2203914</td>
<td align="right">1957</td>
<td align="right">6</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">69.45</td>
<td align="right">-133</td>
<td align="right">18</td>
<td align="left">Y</td>
</tr>

<tr>
<td align="right">77</td>
<td align="left">NWT</td>
<td align="left">YELLOWKNIFE</td>
<td align="left">2204101</td>
<td align="right">1942</td>
<td align="right">7</td>
<td align="right">2018</td>
<td align="right">12</td>
<td align="right">62.47</td>
<td align="right">-114.43</td>
<td align="right">206</td>
<td align="left">Y</td>
</tr>
</tbody>
</table>

<p>We found 13 stations for this province.</p>

<p>We want to work with YELLOWKNIFE station:  stnid = 2204101.</p>

<pre><code class="language-python">stnid = '2204101'   
f1 = open('./'+path+'/'+str(varin)+str(stnid)+'.txt', 'r')
for line in islice(f1, 7):
        print(line)
</code></pre>

<pre><code>2204101,    YELLOWKNIFE    ,  NWT, station joined    , Homogenized daily minimum temperature        , Deg Celcius,          Updated to December 2018

2204101,    YELLOWKNIFE    ,  NWT, station jointe    , Temperature quotidienne minimale homogeneisee, Deg Celcius, Mise a jour jusqu a decembre 2018

 Year Mo  Day 01  Day 02  Day 03  Day 04  Day 05  Day 06  Day 07  Day 08  Day 09  Day 10  Day 11  Day 12  Day 13  Day 14  Day 15  Day 16  Day 17  Day 18  Day 19  Day 20  Day 21  Day 22  Day 23  Day 24  Day 25  Day 26  Day 27  Day 28  Day 29  Day 30  Day 31

Annee Mo Jour 01 Jour 02 Jour 03 Jour 04 Jour 05 Jour 06 Jour 07 Jour 08 Jour 09 Jour 10 Jour 11 Jour 12 Jour 13 Jour 14 Jour 15 Jour 16 Jour 17 Jour 18 Jour 19 Jour 20 Jour 21 Jour 22 Jour 23 Jour 24 Jour 25 Jour 26 Jour 27 Jour 28 Jour 29 Jour 30 Jour 31

 1942  7    12.2    13.3    11.7    10.0     9.4    11.7    14.4    14.4    13.3    12.2    10.6    11.7    11.1    12.8    14.4    15.0    13.9    14.4    13.9    14.4    13.9    13.3    11.7    12.2    11.1    12.2    13.3    10.0    10.6    11.7     8.3 

 1942  8     7.8     5.0     9.4    12.8     9.4     9.4    10.0    10.6    12.8    10.6    12.2    12.2     9.4    15.0    12.8    11.7    14.4    14.4    11.7     8.3     9.4     7.8    12.2     8.9     3.9     7.2    10.6    11.1     7.2     5.0     3.3 

 1942  9     3.9     6.1     6.1     8.3     9.4    11.1    11.1     6.7     6.1     9.4     5.0     9.4     7.2     4.4     5.0     4.4     3.3     1.1     2.2    -0.6    -2.2     0.0    -1.7     1.1    -4.4    -0.6     0.0    -0.6     1.7     1.1 -9999.9M
</code></pre>

<h3 id="cleaning-data">Cleaning data:</h3>

<p>We see that in our dataset we have for each line the daily data by year and by month according to the structure:</p>

<p style="color:blue;font-size:12px;">  Year Mo  Day 01  Day 02  Day 03  Day 04  Day 05  Day 06  Day 07  Day 08  Day 09  Day 10  Day 11  Day 12  Day 13  Day 14  Day 15  Day 16  Day 17  Day 18  Day 19  Day 20  Day 21  Day 22  Day 23  Day 24  Day 25  Day 26  Day 27  Day 28  Day 29  Day 30  Day 31 </p>  

<p>There is a 4 rows header. We will delete this header and also delete the alphanumeric characters, clean the missing values and create a dataframe.</p>

<pre><code class="language-python">f1 = open('./'+path+'/'+str(varin)+str(stnid)+'.txt', 'r')
f2 = open('./tmp.txt', 'w')
for line in f1:
    for word in line:
            if word == 'M':
                f2.write(word.replace('M', ' '))
            elif word == 'a':
                f2.write(word.replace('a', ' '))                    
            else:
                f2.write(word)
f1.close()
f2.close()      
df_station = pd.read_csv('./tmp.txt', delim_whitespace=True, skiprows = range(0, 4))
df_station.head()
</code></pre>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="right">1942</th>
<th align="right">7</th>
<th align="right">12.2</th>
<th align="right">13.3</th>
<th align="right">11.7</th>
<th align="right">10.0</th>
<th align="right">9.4</th>
<th align="right">11.7.1</th>
<th align="right">14.4</th>
<th align="right">14.4.1</th>
<th align="right">13.3.1</th>
<th align="right">12.2.1</th>
<th align="right">10.6</th>
<th align="right">11.7.2</th>
<th align="right">11.1</th>
<th align="right">12.8</th>
<th align="right">14.4.2</th>
<th align="right">15.0</th>
<th align="right">13.9</th>
<th align="right">14.4.3</th>
<th align="right">13.9.1</th>
<th align="right">14.4.4</th>
<th align="right">13.9.2</th>
<th align="right">13.3.2</th>
<th align="right">11.7.3</th>
<th align="right">12.2.2</th>
<th align="right">11.1.1</th>
<th align="right">12.2.3</th>
<th align="right">13.3.3</th>
<th align="right">10.0.1</th>
<th align="right">10.6.1</th>
<th align="right">11.7.4</th>
<th align="right">8.3</th>
</tr>
</thead>

<tbody>
<tr>
<td align="right">0</td>
<td align="right">1942</td>
<td align="right">8</td>
<td align="right">7.8</td>
<td align="right">5</td>
<td align="right">9.4</td>
<td align="right">12.8</td>
<td align="right">9.4</td>
<td align="right">9.4</td>
<td align="right">10</td>
<td align="right">10.6</td>
<td align="right">12.8</td>
<td align="right">10.6</td>
<td align="right">12.2</td>
<td align="right">12.2</td>
<td align="right">9.4</td>
<td align="right">15</td>
<td align="right">12.8</td>
<td align="right">11.7</td>
<td align="right">14.4</td>
<td align="right">14.4</td>
<td align="right">11.7</td>
<td align="right">8.3</td>
<td align="right">9.4</td>
<td align="right">7.8</td>
<td align="right">12.2</td>
<td align="right">8.9</td>
<td align="right">3.9</td>
<td align="right">7.2</td>
<td align="right">10.6</td>
<td align="right">11.1</td>
<td align="right">7.2</td>
<td align="right">5</td>
<td align="right">3.3</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">1942</td>
<td align="right">9</td>
<td align="right">3.9</td>
<td align="right">6.1</td>
<td align="right">6.1</td>
<td align="right">8.3</td>
<td align="right">9.4</td>
<td align="right">11.1</td>
<td align="right">11.1</td>
<td align="right">6.7</td>
<td align="right">6.1</td>
<td align="right">9.4</td>
<td align="right">5</td>
<td align="right">9.4</td>
<td align="right">7.2</td>
<td align="right">4.4</td>
<td align="right">5</td>
<td align="right">4.4</td>
<td align="right">3.3</td>
<td align="right">1.1</td>
<td align="right">2.2</td>
<td align="right">-0.6</td>
<td align="right">-2.2</td>
<td align="right">0</td>
<td align="right">-1.7</td>
<td align="right">1.1</td>
<td align="right">-4.4</td>
<td align="right">-0.6</td>
<td align="right">0</td>
<td align="right">-0.6</td>
<td align="right">1.7</td>
<td align="right">1.1</td>
<td align="right">-9999.9</td>
</tr>

<tr>
<td align="right">2</td>
<td align="right">1942</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">4.4</td>
<td align="right">1.7</td>
<td align="right">5</td>
<td align="right">3.3</td>
<td align="right">-1.1</td>
<td align="right">4.4</td>
<td align="right">2.2</td>
<td align="right">3.9</td>
<td align="right">1.7</td>
<td align="right">5</td>
<td align="right">0.6</td>
<td align="right">-2.8</td>
<td align="right">-1.1</td>
<td align="right">2.8</td>
<td align="right">-1.1</td>
<td align="right">-1.1</td>
<td align="right">2.8</td>
<td align="right">0.6</td>
<td align="right">-2.8</td>
<td align="right">-2.8</td>
<td align="right">-6.7</td>
<td align="right">-10.6</td>
<td align="right">-11.1</td>
<td align="right">-7.2</td>
<td align="right">-2.2</td>
<td align="right">-1.7</td>
<td align="right">-1.1</td>
<td align="right">-3.9</td>
<td align="right">-5</td>
<td align="right">-8.3</td>
</tr>

<tr>
<td align="right">3</td>
<td align="right">1942</td>
<td align="right">11</td>
<td align="right">-11.7</td>
<td align="right">-13.9</td>
<td align="right">-13.3</td>
<td align="right">-12.8</td>
<td align="right">-12.8</td>
<td align="right">-12.8</td>
<td align="right">-12.2</td>
<td align="right">-17.8</td>
<td align="right">-12.2</td>
<td align="right">-21.1</td>
<td align="right">-16.1</td>
<td align="right">-16.1</td>
<td align="right">-17.8</td>
<td align="right">-11.1</td>
<td align="right">-22.2</td>
<td align="right">-25</td>
<td align="right">-25</td>
<td align="right">-22.8</td>
<td align="right">-17.8</td>
<td align="right">-23.9</td>
<td align="right">-26.7</td>
<td align="right">-13.9</td>
<td align="right">-18.3</td>
<td align="right">-26.7</td>
<td align="right">-32.2</td>
<td align="right">-31.1</td>
<td align="right">-34.4</td>
<td align="right">-26.7</td>
<td align="right">-30</td>
<td align="right">-27.2</td>
<td align="right">-9999.9</td>
</tr>

<tr>
<td align="right">4</td>
<td align="right">1942</td>
<td align="right">12</td>
<td align="right">-23.9</td>
<td align="right">-20.6</td>
<td align="right">-20.6</td>
<td align="right">-25</td>
<td align="right">-20.6</td>
<td align="right">-20.6</td>
<td align="right">-26.1</td>
<td align="right">-27.8</td>
<td align="right">-30</td>
<td align="right">-31.1</td>
<td align="right">-28.9</td>
<td align="right">-23.9</td>
<td align="right">-25</td>
<td align="right">-31.1</td>
<td align="right">-33.9</td>
<td align="right">-37.2</td>
<td align="right">-37.8</td>
<td align="right">-38.9</td>
<td align="right">-40.6</td>
<td align="right">-39.4</td>
<td align="right">-33.3</td>
<td align="right">-35</td>
<td align="right">-35.6</td>
<td align="right">-33.9</td>
<td align="right">-26.1</td>
<td align="right">-31.7</td>
<td align="right">-34.4</td>
<td align="right">-28.9</td>
<td align="right">-24.4</td>
<td align="right">-33.9</td>
<td align="right">-40.6</td>
</tr>
</tbody>
</table>

<p>That&rsquo;s better but we still have some missing values. We will also change column names.</p>

<pre><code class="language-python">df_station.columns = ['Year', 'Month', 'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10',
                                  'D11','D12','D13','D14','D15','D16','D17','D18','D19','D20',
                                  'D21','D22','D23','D24','D25','D26','D27','D28','D29','D30','D31']
     
os.remove(&quot;./tmp.txt&quot;)
   
   # nettoyage des valeurs manquantes 
try:  
    df_station = df_station.replace({'E':''}, regex=True)
except:
       pass
try: 
    df_station = df_station.replace({'a':''}, regex=True)
except:
       pass
try:     
    df_station = df_station.replace({'-9999.9':''}, regex=True)
except:
       pass
try:     
    df_station = df_station.replace({-9999.9:''}, regex=True)
except:
       pass    
    
for col in  df_station.columns[2:]:
       df_station[col] = pd.to_numeric(df_station[col], errors='coerce')      
</code></pre>

<pre><code class="language-python">df_station.head()
</code></pre>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="right">Year</th>
<th align="right">Month</th>
<th align="right">D1</th>
<th align="right">D2</th>
<th align="right">D3</th>
<th align="right">D4</th>
<th align="right">D5</th>
<th align="right">D6</th>
<th align="right">D7</th>
<th align="right">D8</th>
<th align="right">D9</th>
<th align="right">D10</th>
<th align="right">D11</th>
<th align="right">D12</th>
<th align="right">D13</th>
<th align="right">D14</th>
<th align="right">D15</th>
<th align="right">D16</th>
<th align="right">D17</th>
<th align="right">D18</th>
<th align="right">D19</th>
<th align="right">D20</th>
<th align="right">D21</th>
<th align="right">D22</th>
<th align="right">D23</th>
<th align="right">D24</th>
<th align="right">D25</th>
<th align="right">D26</th>
<th align="right">D27</th>
<th align="right">D28</th>
<th align="right">D29</th>
<th align="right">D30</th>
<th align="right">D31</th>
</tr>
</thead>

<tbody>
<tr>
<td align="right">0</td>
<td align="right">1942</td>
<td align="right">8</td>
<td align="right">7.8</td>
<td align="right">5</td>
<td align="right">9.4</td>
<td align="right">12.8</td>
<td align="right">9.4</td>
<td align="right">9.4</td>
<td align="right">10</td>
<td align="right">10.6</td>
<td align="right">12.8</td>
<td align="right">10.6</td>
<td align="right">12.2</td>
<td align="right">12.2</td>
<td align="right">9.4</td>
<td align="right">15</td>
<td align="right">12.8</td>
<td align="right">11.7</td>
<td align="right">14.4</td>
<td align="right">14.4</td>
<td align="right">11.7</td>
<td align="right">8.3</td>
<td align="right">9.4</td>
<td align="right">7.8</td>
<td align="right">12.2</td>
<td align="right">8.9</td>
<td align="right">3.9</td>
<td align="right">7.2</td>
<td align="right">10.6</td>
<td align="right">11.1</td>
<td align="right">7.2</td>
<td align="right">5</td>
<td align="right">3.3</td>
</tr>

<tr>
<td align="right">1</td>
<td align="right">1942</td>
<td align="right">9</td>
<td align="right">3.9</td>
<td align="right">6.1</td>
<td align="right">6.1</td>
<td align="right">8.3</td>
<td align="right">9.4</td>
<td align="right">11.1</td>
<td align="right">11.1</td>
<td align="right">6.7</td>
<td align="right">6.1</td>
<td align="right">9.4</td>
<td align="right">5</td>
<td align="right">9.4</td>
<td align="right">7.2</td>
<td align="right">4.4</td>
<td align="right">5</td>
<td align="right">4.4</td>
<td align="right">3.3</td>
<td align="right">1.1</td>
<td align="right">2.2</td>
<td align="right">-0.6</td>
<td align="right">-2.2</td>
<td align="right">0</td>
<td align="right">-1.7</td>
<td align="right">1.1</td>
<td align="right">-4.4</td>
<td align="right">-0.6</td>
<td align="right">0</td>
<td align="right">-0.6</td>
<td align="right">1.7</td>
<td align="right">1.1</td>
<td align="right">-9999.9</td>
</tr>

<tr>
<td align="right">2</td>
<td align="right">1942</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">4.4</td>
<td align="right">1.7</td>
<td align="right">5</td>
<td align="right">3.3</td>
<td align="right">-1.1</td>
<td align="right">4.4</td>
<td align="right">2.2</td>
<td align="right">3.9</td>
<td align="right">1.7</td>
<td align="right">5</td>
<td align="right">0.6</td>
<td align="right">-2.8</td>
<td align="right">-1.1</td>
<td align="right">2.8</td>
<td align="right">-1.1</td>
<td align="right">-1.1</td>
<td align="right">2.8</td>
<td align="right">0.6</td>
<td align="right">-2.8</td>
<td align="right">-2.8</td>
<td align="right">-6.7</td>
<td align="right">-10.6</td>
<td align="right">-11.1</td>
<td align="right">-7.2</td>
<td align="right">-2.2</td>
<td align="right">-1.7</td>
<td align="right">-1.1</td>
<td align="right">-3.9</td>
<td align="right">-5</td>
<td align="right">-8.3</td>
</tr>

<tr>
<td align="right">3</td>
<td align="right">1942</td>
<td align="right">11</td>
<td align="right">-11.7</td>
<td align="right">-13.9</td>
<td align="right">-13.3</td>
<td align="right">-12.8</td>
<td align="right">-12.8</td>
<td align="right">-12.8</td>
<td align="right">-12.2</td>
<td align="right">-17.8</td>
<td align="right">-12.2</td>
<td align="right">-21.1</td>
<td align="right">-16.1</td>
<td align="right">-16.1</td>
<td align="right">-17.8</td>
<td align="right">-11.1</td>
<td align="right">-22.2</td>
<td align="right">-25</td>
<td align="right">-25</td>
<td align="right">-22.8</td>
<td align="right">-17.8</td>
<td align="right">-23.9</td>
<td align="right">-26.7</td>
<td align="right">-13.9</td>
<td align="right">-18.3</td>
<td align="right">-26.7</td>
<td align="right">-32.2</td>
<td align="right">-31.1</td>
<td align="right">-34.4</td>
<td align="right">-26.7</td>
<td align="right">-30</td>
<td align="right">-27.2</td>
<td align="right">-9999.9</td>
</tr>

<tr>
<td align="right">4</td>
<td align="right">1942</td>
<td align="right">12</td>
<td align="right">-23.9</td>
<td align="right">-20.6</td>
<td align="right">-20.6</td>
<td align="right">-25</td>
<td align="right">-20.6</td>
<td align="right">-20.6</td>
<td align="right">-26.1</td>
<td align="right">-27.8</td>
<td align="right">-30</td>
<td align="right">-31.1</td>
<td align="right">-28.9</td>
<td align="right">-23.9</td>
<td align="right">-25</td>
<td align="right">-31.1</td>
<td align="right">-33.9</td>
<td align="right">-37.2</td>
<td align="right">-37.8</td>
<td align="right">-38.9</td>
<td align="right">-40.6</td>
<td align="right">-39.4</td>
<td align="right">-33.3</td>
<td align="right">-35</td>
<td align="right">-35.6</td>
<td align="right">-33.9</td>
<td align="right">-26.1</td>
<td align="right">-31.7</td>
<td align="right">-34.4</td>
<td align="right">-28.9</td>
<td align="right">-24.4</td>
<td align="right">-33.9</td>
<td align="right">-40.6</td>
</tr>
</tbody>
</table>

<p>We can now detect the minimum and maximum recording years and write the daily data on a single column.</p>

<pre><code class="language-python">yearmin = df_station['Year'].min()                                  
yearmax = df_station['Year'].max()                                   
m_start =  df_station['Month'].loc[(df_station['Year'] == yearmin)].min()
m_end   =  df_station['Month'].loc[(df_station['Year'] == yearmax)].max()
d_end = calendar.monthrange(yearmax, m_end)[1]                     

tmp_tmin = [ ] 
for year in range(yearmin,yearmax+1):    ### Loop over years
    for month in range(1,13):
        df = []
        last_day = calendar.monthrange(year, month)[1] 
        tmin = df_station.loc[(df_station[&quot;Year&quot;] == year) &amp; (df_station[&quot;Month&quot;] == month)].iloc[:,2:last_day+2].values
           
        if len(tmin) == 0:
            a = np.empty((calendar.monthrange(year,month)[1]))
            a[:] = np.nan
            df=pd.DataFrame(a)
        else:
            df=pd.DataFrame(tmin.T)
               
        start = date(year, month, 1)
        end =   date(year, month, last_day)
        delta=(end-start) 
        nb_days = delta.days + 1 
        rng = pd.date_range(start, periods=nb_days, freq='D')          
        df['datetime'] = rng
        df.index = df['datetime']
        tmp_tmin.append(df)
           
tmp_tmin = pd.concat(tmp_tmin) 
df = pd.DataFrame({'datetime': tmp_tmin['datetime'], 'Var': tmp_tmin.iloc[:,0]}, columns = ['datetime','Tmin']) 
df.index = df['datetime']
tmp_tmin = tmp_tmin.drop([&quot;datetime&quot;], axis=1)
tmp_tmin.tail()
</code></pre>

<table>
<thead>
<tr>
<th align="left">datetime</th>
<th align="right">0</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">2018-12-27 00:00:00</td>
<td align="right">-32.6</td>
</tr>

<tr>
<td align="left">2018-12-28 00:00:00</td>
<td align="right">-33.3</td>
</tr>

<tr>
<td align="left">2018-12-29 00:00:00</td>
<td align="right">-27.7</td>
</tr>

<tr>
<td align="left">2018-12-30 00:00:00</td>
<td align="right">-35.2</td>
</tr>

<tr>
<td align="left">2018-12-31 00:00:00</td>
<td align="right">-33.8</td>
</tr>
</tbody>
</table>

<h3 id="visualization">Visualization:</h3>

<p>Quick visualization of the monthly average temperatures for the month of January.
We will group the data by month and calculate the average.</p>

<pre><code class="language-python">import matplotlib.pylab as plt
import datetime
month_tmin = tmp_tmin.resample('M').mean()
month_tmin.tail()
</code></pre>

<table>
<thead>
<tr>
<th align="left">datetime</th>
<th align="right">0</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">2018-08-31 00:00:00</td>
<td align="right">8.9871</td>
</tr>

<tr>
<td align="left">2018-09-30 00:00:00</td>
<td align="right">-0.673333</td>
</tr>

<tr>
<td align="left">2018-10-31 00:00:00</td>
<td align="right">-4.99032</td>
</tr>

<tr>
<td align="left">2018-11-30 00:00:00</td>
<td align="right">-15.5233</td>
</tr>

<tr>
<td align="left">2018-12-31 00:00:00</td>
<td align="right">-21.8129</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">tmin_janvier = month_tmin[month_tmin.index.month==1]
tmin_janvier.head()
</code></pre>

<table>
<thead>
<tr>
<th align="left">datetime</th>
<th align="right">0</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">1942-01-31 00:00:00</td>
<td align="right">nan</td>
</tr>

<tr>
<td align="left">1943-01-31 00:00:00</td>
<td align="right">-32.6871</td>
</tr>

<tr>
<td align="left">1944-01-31 00:00:00</td>
<td align="right">-25.471</td>
</tr>

<tr>
<td align="left">1945-01-31 00:00:00</td>
<td align="right">-28.6355</td>
</tr>

<tr>
<td align="left">1946-01-31 00:00:00</td>
<td align="right">-33.4032</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">plt.rcParams[&quot;figure.figsize&quot;]=[10,6]        
plt.plot(tmin_janvier.index, tmin_janvier[:],  label='Tmin Station', linewidth=2, c='r')
plt.title('Monthly mean of daily minimum temperature: January from ' + datetime.date(yearmin, 1, 1).strftime('%Y')+ ' et '  + datetime.date(yearmax, 1, 1).strftime('%Y'), fontsize=15, color='black', weight='semibold')
plt.xlabel('Year', fontsize=15, color='black', weight='semibold')
plt.ylabel('°C', fontsize=15, color='black', weight='semibold')
plt.show()
</code></pre>

<p><img src="output_20_0.png" alt="png" /></p>

<h2 id="final-code">Final code</h2>

<p>The following code retrieves all stations for a specific province but for a common period.</p>

<p>For example, we wish to extract all daily temperature data for the province of the Northwest Territories but only for the common period 1989-2018.</p>

<p>We wish to have one file per station.</p>

<pre><code class="language-python">import pandas as pd
import os
from datetime import date
import calendar
import numpy as np
import pathlib

################################################                                                            #
varin = 'dn'                                                                  
path = 'Homog_daily_min_temp_v2018'                                           
varout = 'Tasmoy'
province = 'NWT'  
yearmin = 1989 
yearmax = 2018
###############################################################################

dataframe = pd.read_excel(&quot;./Temperature_Stations.xls&quot;, skiprows = range(0, 3))

globals()['dataframe_'+province] = dataframe.loc[(dataframe[&quot;Prov&quot;] == province) &amp; (dataframe[&quot;année déb.&quot;] &lt;= yearmin) &amp; (dataframe[&quot;année fin.&quot;] &gt;= yearmax),:]

names = []
for i, row in globals()['dataframe_'+province].iterrows():
   stnid = row['stnid']   
   f1 = open('./'+path+'/'+str(varin)+str(stnid)+'.txt', 'r')
   f2 = open('./tmp.txt', 'w')

   for line in f1:
        for word in line:
            if word == 'M':
                f2.write(word.replace('M', ' '))
            elif word == 'a':
                f2.write(word.replace('a', ' '))                    
            else:
                f2.write(word)
   f1.close()
   f2.close()
          
   station = pd.read_csv('./tmp.txt', delim_whitespace=True, skiprows = range(0, 4))
   
   station.columns = ['Annee', 'Mois', 'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10',
                                  'D11','D12','D13','D14','D15','D16','D17','D18','D19','D20',
                                  'D21','D22','D23','D24','D25','D26','D27','D28','D29','D30','D31']
     
   os.remove(&quot;./tmp.txt&quot;)
 
   try:  
       station = station.replace({'E':''}, regex=True)
   except:
       pass
   try: 
       station = station.replace({'a':''}, regex=True)
   except:
       pass
   try:     
       station = station.replace({'-9999.9':''}, regex=True)
   except:
       pass
   try:     
       station = station.replace({-9999.9:''}, regex=True)
   except:
       pass    
       
   for col in  station.columns[2:]:
       station[col] = pd.to_numeric(station[col], errors='coerce')
        
   m_start =  station['Mois'].loc[(station['Annee'] == yearmin)].min()
   m_end   =  station['Mois'].loc[(station['Annee'] == yearmax)].max()
   
   d_end = calendar.monthrange(yearmax, m_end)[1]
     
   tmp_tmin = [ ] 
   for year in range(yearmin,yearmax+1):    ### Boucle sur les annees
       for month in range(1,13):
           df = []
           last_day = calendar.monthrange(year, month)[1] 
           tmin = station.loc[(station[&quot;Annee&quot;] == year) &amp; (station[&quot;Mois&quot;] == month)].iloc[:,2:last_day+2].values
           
           if len(tmin) == 0:
               a = np.empty((calendar.monthrange(year,month)[1]))
               a[:] = np.nan
               df=pd.DataFrame(a)
           else:
               df=pd.DataFrame(tmin.T)
               
           start = date(year, month, 1)
           end =   date(year, month, last_day)
           delta=(end-start) 
           nb_days = delta.days + 1 
           rng = pd.date_range(start, periods=nb_days, freq='D')          
           df['datetime'] = rng
           df.index = df['datetime']
           tmp_tmin.append(df)
           
   tmp_tmin = pd.concat(tmp_tmin) 
   df = pd.DataFrame({'datetime': tmp_tmin['datetime'], 'Var': tmp_tmin.iloc[:,0]}, columns = ['datetime','Tmin']) 
   df.index = df['datetime']
   tmp_tmin = tmp_tmin.drop([&quot;datetime&quot;], axis=1)
      
   name = row['Nom de station'].replace(' ','_')
   name = name.replace(&quot;'&quot;,'')
   names.append(name)
   mypath='./Daily_data_by_Province/'+varout+'/'
   pathlib.Path(mypath).mkdir(parents=True, exist_ok=True)
   
   tmp_tmin.to_csv(mypath+name+'_daily_'+varout+'_'+str(yearmin)+'-'+str(yearmax)+'.csv')
         
latlon = pd.DataFrame({'Latitude': globals()['dataframe_'+province][&quot;lat (deg)&quot;], 'Longitude': globals()['dataframe_'+province][&quot;long (deg)&quot;] }, columns = ['Latitude','Longitude']) 
latlon.to_csv('./Daily_data_by_Province/stations_latlon_'+province+'.csv')
names = pd.DataFrame(names)
names.to_csv('./Daily_data_by_Province/stations_noms_'+province+'.csv')

base_filename = './Daily_data_by_Province/stations_noms_'+province+'.txt'
names[0].to_csv(base_filename, sep='\t', index = False) 
</code></pre>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/eccc_temp/&amp;text=ECCC%20homogenized%20dataset" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/eccc_temp/&amp;t=ECCC%20homogenized%20dataset" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=ECCC%20homogenized%20dataset&amp;body=/post/eccc_temp/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/eccc_temp/&amp;title=ECCC%20homogenized%20dataset" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=ECCC%20homogenized%20dataset%20/post/eccc_temp/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/eccc_temp/&amp;title=ECCC%20homogenized%20dataset" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hued2496a182fbb6fc8c711157078d29a6_5348924_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/">Guillaume Dueymes</a></h5>
      <h6 class="card-subtitle">Data Scientist and Research Assistant</h6>
      <p class="card-text">My research interests include data science, data management and climate science.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.researchgate.net/profile/Guillaume_Dueymes" target="_blank" rel="noopener">
        <i class="fab fa-researchgate"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/guimeto" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  



  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.bcfae8267aba63cc55af53a503896bd9.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
